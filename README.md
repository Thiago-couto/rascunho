

**1- Gênero**

- Moda: Masculino (2206)

<img src=https://github.com/user-attachments/assets/9ca5090f-f8a9-464c-920d-839a9f75c360 width="900"/>  

- Masculino: 75.9%  
- Feminino: 23.6%  
- preferiu não informar: 0.3%  
- outros: 0.1%  

**2- Faixa Etária**

<img src=https://github.com/user-attachments/assets/1b56c17f-92e2-47af-99c1-276b95ccfeaa width="900"/>  

- Moda: 25-29 (1084)  
- Média: 30 anos  
- Mediana: 29 anos  
- 1º Quartil (Q1): 26 anos    
- 3º Quartil (Q3): 34 anos  
- Variância: 84,36   
- Desvio-padrão: 9,19 anos   

**3- Faixa Salarial**

<img src=https://github.com/user-attachments/assets/9c8a4581-f9be-48c3-8785-5aac4c6c3b76 width="900"/>  

- Moda: 8.001-12.000 (733)      
- Média: 8904.71     
- Mediana: R$7,000.50     
- 1º Quartil (Q1): R$5,000.50      
- 3º Quartil (Q3): R$10,000.50  

**4- Nível de experiência**

- Moda: 1 a 2 anos (897)

<img src=https://github.com/user-attachments/assets/fd058b9f-1ad4-4dfd-880e-ccf80b0408fc width="900"/>  

- menos que 1 ano: 9.7%
- 1 a 2 anos: 30.9%  
- 3 a 4 anos: 27.1%  
- 4 a 5 anos: 10.1%
- 5 a 6 anos: 7.8%
- 7 a 10 anos: 7.2%
- mais que 10 anos: 6.81% 
- não possui experiência: 0.2%

**5- Ciêntista por Estado**

Moda: São Paulo (SP) - (1126)

<img src=https://github.com/user-attachments/assets/f9bf37e4-c038-47b5-a761-6032e8e0bb93 width="900"/> 

**6- Raça/Etnia/Cor**

- Moda: Branca (1876)

<img src=https://github.com/user-attachments/assets/e7641f7c-0676-4fab-afc7-a802e5ef3575 width="900"/>  

- Branca: 64.5%  
- Parda: 24.1%  
- Amarela: 2.9%  
- preta: 7.3%  
- preferiu não informar: 0.8%  
- outra: 0.2%  
- Indígena: 0.2%  

**7- Ciêntistas por Região**

- Moda: Sudeste (1772)

<img src=https://github.com/user-attachments/assets/8bc2cda6-fc01-45a4-9e44-cb7faf61939b width="900"/>   

- Sudeste: 61.0%  
- Sul: 20.0%  
- Nordeste: 11.2%  
- Centro-Oeste: 6.3%  
- Norte: 1.4%  

**8- Nível de Ensino**

- Moda: Graduação/Bacharelado (1130)

<img src=https://github.com/user-attachments/assets/99583953-cdcb-4eb3-9e12-01f918271ddb width="900"/>  

- Graduação/Bacharelado: 38.9%  
- Pós-Graduação: 32.0%     
- Mestrado: 12.8%   
- Doutorado ou Phd: 3.9%  
- Estudante Graduação: 12.5
- 
**9- Situação Empresarial**

- Moda: Empregado(CLT) - (2326)

<img src=https://github.com/user-attachments/assets/f8ecaa96-2cfc-453d-9ce4-facf7b70fad9 width="900"/>  

- Empregado(CLT): 80.0%  
- Empregado(CNPJ): 9.0%  
- Estagiário: 5.8%  
- Empresa de fora do Brasil: 2.8%  
- Servidor Público: 1.8%  
- Freelancer: 0.5%
- Prefiro não informar: 0.1% 

**10- Cargo**

- Moda: Analista de Dados (874)

<img src=https://github.com/user-attachments/assets/a1c350b1-cf45-4049-9af0-8be13b72ec71 width="900"/>  

- Analista de Dados: 30.1%
- Cientista de Dados: 22.9%  
- Engenheiro de Dados: 22.4%  
- Analista de BI: 16.8%
- Data Product Manager: 2.7%  
- Engenheiro de machine learning: 2.5%  
- Estatístico: 0.7%  
- Analista de Inteligência de Mercado: 1.3%  
- Administrador de Banco de Dados: 0.6%  

**11- Área de Formação**

- Moda: Computação (1231)

<img src=https://github.com/user-attachments/assets/d5b26502-484e-4fdd-ab5f-d63730361761 width="900"/>  

- Computação: 42.3%  
- Outras Engenharias: 22.7%   
- Economia: 13.7%     
- Estatística: 7.9%  
- Outra opção: 4.8%   
- Química / Física: 3.0%  
- Marketing: 1.9%  
- Ciências Biológicas: 2.0%  
- Ciências Sociais: 1.6%    


Gráficos com 2 variáveis:   
- Área de Formação / Faixa Salarial   
<img src=https://github.com/user-attachments/assets/6bbf7696-bf2f-4089-be72-ab5b760984d7 width="900"/>   

- Idade / Gênero 
<img src=https://github.com/user-attachments/assets/d1451c58-0cb5-483d-bc4d-646ec5b01f07 width="900">  

- Nível de experiência / Cargo atual 
<img src=https://github.com/user-attachments/assets/1f8bfe62-e667-463c-9900-281723ec4456 width="900">  

- Faixa Etária/Nível na Empresa  
<img src=https://github.com/user-attachments/assets/0a74d5dc-13f1-4cc2-9992-959ac2ab19d7 width="900">  

- Nível na Empresa/Salário  
<img src=https://github.com/user-attachments/assets/03aacc34-766c-49c2-afcb-168b67c4d63b width="900">   

- **Gráfico base auxiliar**      
<img src=https://github.com/user-attachments/assets/08a5812f-1697-481a-add7-38c93b236c07 width="600">     
 
Curso de Ciência de Dados por Estado (código)       
- SP - 1521433; 1536760; 1538622; 1543013; 1545554; 1589553; 1599656; 1603036; 1618685; (9)    
- MG - 1600504; (1)    
- CE - 1127861; 1571410 (2)   
- PB - 1550460; (1)      

Modelo 1: Algoritmo
Substitua o título pelo nome do algoritmo que será utilizado. P. ex. árvore de decisão, rede neural, SVM, etc. Justifique a escolha do modelo. Apresente o processo utilizado para amostragem de dados (particionamento, cross-validation). Descreva os parâmetros utilizados. Apresente trechos do código utilizado comentados. Se utilizou alguma ferramenta gráfica, apresente imagens com o fluxo de processamento.

Modelo 2: Algoritmo
Repita os passos anteriores para o segundo modelo.

# **Resultados**   

- Visualização da matriz de confusão (treino)     
![image](https://github.com/user-attachments/assets/eec412cf-1a4d-4c7e-9a07-6bdb414b5bc5)   
Treino: 0.7289 -> O modelo acerta aproximadamente 72.9%.     

- Visualização da matriz de confusão (teste)    
![image](https://github.com/user-attachments/assets/bed24ec5-8515-4859-ae8f-c1ca84aa801b)    
Teste: 0.6795 -> O modelo acerta aproximadamente 67.9%.    

# **Precisão treino**       

| Classe  | Precision | Recall | F1-Score | Support |
|---------|-----------|--------|----------|---------|
| Júnior  | 0.71      | 0.84   | 0.77     | 591     |
| Pleno   | 0.66      | 0.61   | 0.63     | 801     |
| Sênior  | 0.82      | 0.77   | 0.79     | 788     |    

**Acurácia geral:** 0.73

|             | Precision | Recall | F1-Score | Support |
|-------------|-----------|--------|----------|---------|
| Macro Avg   | 0.73      | 0.74   | 0.73     | 2180    |
| Weighted Avg| 0.73      | 0.73   | 0.73     | 2180    |

# **Precisão teste**  

| Classe  | Precision | Recall | F1-Score | Support |
|---------|-----------|--------|----------|---------|
| Júnior  | 0.66      | 0.84   | 0.74     | 171     |
| Pleno   | 0.62      | 0.55   | 0.58     | 280     |
| Sênior  | 0.76      | 0.71   | 0.73     | 276     |  

**Acurácia geral:** 0.68

|             | Precision | Recall | F1-Score | Support |
|-------------|-----------|--------|----------|---------|
| Macro Avg   | 0.68      | 0.70   | 0.68     | 727     |
| Weighted Avg| 0.68      | 0.68   | 0.68     | 727     |    

- O modelo de teste apresentou uma queda na Acurácia, principalmente devido a classe Pleno.

# **Árvore de decisão finalizada**    
![image](https://github.com/user-attachments/assets/7f53abc8-3d15-4df8-8a27-e8d4e15c86d4)    


# **Interpretação do modelo 1**      
- O modelo utilizado foi o `DecisionTreeClassifier` para a árvore de decisão.
- Os parâmetros principais `max_depth=5`, `test_size=0.25`. (Para o ajuste da profundidade da árvore e a separação de 25% dos dados para o conjunto de teste e 75% dos dados para o conjunto de treino).  
- O modelo primeiramente faz uma limpeza de dados (dropando atributos) para que os atributos irrelevantes não influenciem na tomada de decisão.
- Em segundo lugar, os dados relevantes foram transformados em numéricos, para a execução da árvore de decisão.
- O atributo nível profissional e de ensino é transformado em númerico crescente, enquanto o de gênero é transformado em númerico binário (0 = Júnior, 1 = Pleno e 2 = Sênior) (0 = Masculino e 1 = Feminino). 
- O atributo que mais influenciou na tomada de decisão do modelo, foi a Faixa Salarial.
- A partir, da ánalise da precisão de treinos e testes, é possível observar que o modelo é mais adequado para identificar Juniores e Seniores do que Plenos. Essa ánalise se deve a precisão e o desempenho que os níveis obtiveram.   
- O modelo apresenta overfitting, devido ao fato do treino possuir acurácia maior que o teste, porém pela diferença entre treino e teste não ser alta (aproximadamente 5%), ele apresenta somente um pequeno overfitting.   
- Pleno por apresentar um baixo recall, se torna mais díficil de identificar, fator que leva o modelo a confundir Pleno com as outras classes algumas vezes.   
- O modelo em sí apresenta 68% de acerto nas classificações de níveis.  

**Possíveis Melhoras:**  
- Ajustes hiperparâmetros (ajudar a diferenciação entre Júnior, Pleno e Sênior).  
- Observar quais atributos foram mais importantes para escolha dos níveis.
- Balancear os dados.

**Conclusão:**   
O modelo é razoável, porém pode ser melhorado. Ele apresenta diversas falhas, principalmente na classificação dos níveis, as quais diminuem a porcentagem de acertos. O modelo também apresenta acerto maiores no treino do que nos testes, sendo estes aproximados, indicando um leve overfiting . Logo, com certos ajustes e melhorias, o modelo tende a se tornar equilibrado.

# **Resultados obtidos com o modelo 2.**    
- Visualização da matriz de confusão (treino)     
![image](https://github.com/user-attachments/assets/2d330b06-3f4d-4af6-a995-6426a42155ba)     
Treino: 0.8914 -> O modelo acerta aproximadamente 89.1%.     

- Visualização da matriz de confusão (teste)    
![image](https://github.com/user-attachments/assets/96a9cd2c-d187-484e-b5e4-9cf0f1ce6597)    
Teste: 0.7120 -> O modelo acerta aproximadamente 71.2%.     

# **Precisão treino**       

| Classe  | Precision | Recall | F1-Score | Support |
|---------|-----------|--------|----------|---------|
| Júnior  | 0.95      | 0.86   | 0.90     | 534     |
| Pleno   | 0.83      | 0.90   | 0.86     | 769     |
| Sênior  | 0.92      | 0.91   | 0.92     | 760     |    

**Acurácia geral:** 0.89 

|             | Precision | Recall | F1-Score | Support |
|-------------|-----------|--------|----------|---------|
| Macro Avg   | 0.90      | 0.89   | 0.89     | 2063    |
| Weighted Avg| 0.89      | 0.89   | 0.89     | 2063    |

# **Precisão teste**  

| Classe  | Precision | Recall | F1-Score | Support |
|---------|-----------|--------|----------|---------|
| Júnior  | 0.77      | 0.68   | 0.72     | 228     |
| Pleno   | 0.61      | 0.67   | 0.64     | 312     |
| Sênior  | 0.80      | 0.78   | 0.79     | 304     |  

**Acurácia geral:** 0.71 

|             | Precision | Recall | F1-Score | Support |
|-------------|-----------|--------|----------|---------|
| Macro Avg   | 0.72      | 0.71   | 0.72     | 844     |
| Weighted Avg| 0.72      | 0.71   | 0.71     | 844     |    

- O modelo de teste apresentou uma queda na Acurácia, principalmente devido a classe Pleno.  

# **Random Forest finalizada**    
![download](https://github.com/user-attachments/assets/2bc3dbe9-56b2-4457-8451-12da9e1b2177)    
  

# **Interpretação do modelo 2**    
- O modelo utilizado foi o `RandomForestClassifier` para a Floresta aleatória.
- O principal objetivo é a classificação dos níveis (Júnior, Pleno, Sênior), com base em atributos do perfil do indivíduo.   
- Os parâmetros principais `n_estimators=100`, `max_depth=10`, `test_size=0.29` (Para o número de árvores, ajuste da profundidade da árvore e a separação de 29% dos dados para o conjunto de teste e 71% dos dados para o conjunto de treino).
- O modelo primeiramente faz uma limpeza de dados (dropando atributos) para que os atributos irrelevantes não influenciem na tomada de decisão.
- Em segundo lugar, ele define os níveis profissionais e de ensino em números crescentes e define o gênero para número binários (0 = Júnior, 1 = Pleno e 2 = Sênior) (0 = Masculino e 1 = Feminino).   
- O modelo apresenta uma divisão de dados aleatória para cada árvore de decisão formada, em que cada nó um conjunto aleatório de atributos é testado.    
- O modelo possui como atributo mais influente para a tomada de decisão, a Idade e o setor no qual o indivíduo trabalha.    
- O modelo de Random Forest apresenta overfitting, já que a diferença entre treino e teste é alta (aproximadamente 18%).   
- Pleno apresenta uma queda na precisão, demonstrando que o modelo possui dificuldade em acertar e identificar a classe Pleno.   
- O modelo em sí apresenta 71% de acerto nas classificações de níveis.  

**Possíveis Melhoras:**  
- Ajustes hiperparâmetros (ajudar a diferenciação entre Júnior, Pleno e Sênior).  
- Remover mais atributos que sejam irrelevantes.
- Reduzir a complexidade do modelo (diminuindo a profundidade de cada árvore)
- Balancear os dados.

**Conclusão:**   
O modelo é razoável porém precisa ser melhorado, ele continua tendo dificuldade na identificação de classes, fator o qual diminui a acurácia geral e compromete no resultado final do modelo. Um dos principais fatores que levam ao desequilibrio do modelo, se deve a quantidade de atributos utilizados. O modelo possui baixa precisão na classe Pleno, fator que precisa ser melhorado. Logo com certas melhorias o modelo tende a se tornar equilibrado para a classificação dos níveis profissionais.


- **Parâmetros utilizados:**            
Foi definido `test_size=0.25` -> uma quantidade de dados para treino de 75% e 25% vão para teste.    
`modelo.feature_importances_` -> para a avaliação dos atributos de mais importância na tomada de decisão do modelo.  
`ccp_alpha=0.006` -> controle de overfitting.  
`max_depth=5` -> para a profundidade da árvore.

- **Trechos do Código:**  
```python
`from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier

X_treino, X_teste, y_treino, y_teste = train_test_split(
    df.drop(columns=['Nível']), df['Nível'], test_size=0.25, random_state=42
)

modelo = DecisionTreeClassifier(
    criterion='gini', ccp_alpha=0.006, max_depth=5, random_state=42
)
modelo.fit(X_treino, y_treino)`
```

```python
`accuracy_score(y_teste, previsoesTeste)
accuracy_score(y_treino, previsoesTreino)

cm = ConfusionMatrix(modelo)
cm.fit(X_treino, y_treino)
cm.score(X_treino, y_treino)

cm = ConfusionMatrix(modelo)
cm.fit(X_treino, y_treino)
cm.score(X_teste, y_teste)`
```    
- Mostra a acurácia e as matrizes de confusão de teste e treino.  

